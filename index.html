<!doctype html>



  


<html class="theme-next muse use-motion" lang="zh-Hans">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>



<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.0" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="Hexo, NexT" />




  


  <link rel="alternate" href="/atom.xml" title="Mikito" type="application/atom+xml" />




  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.1.0" />






<meta name="description" content="Computer Science">
<meta property="og:type" content="website">
<meta property="og:title" content="Mikito">
<meta property="og:url" content="http://115.159.44.202/index.html">
<meta property="og:site_name" content="Mikito">
<meta property="og:description" content="Computer Science">
<meta property="og:locale" content="zh-Hans">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Mikito">
<meta name="twitter:description" content="Computer Science">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    sidebar: {"position":"left","display":"post","offset":12,"offset_float":0,"b2t":false,"scrollpercent":false},
    fancybox: true,
    motion: true,
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://115.159.44.202/"/>





  <title> Mikito </title>
</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  














  
  
    
  

  <div class="container one-collumn sidebar-position-left 
   page-home 
 ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Mikito</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://115.159.44.202/2017/11/10/机器学习/Andrew/Machine Learning 第三周/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Mikito">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Mikito">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/11/10/机器学习/Andrew/Machine Learning 第三周/" itemprop="url">
                  Machine Learning 第三周
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-11-10T14:50:48+08:00">
                2017-11-10
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/机器学习/" itemprop="url" rel="index">
                    <span itemprop="name">机器学习</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="Week-3"><a href="#Week-3" class="headerlink" title="Week 3"></a>Week 3</h1><h1 id="PROGRAMMING"><a href="#PROGRAMMING" class="headerlink" title="PROGRAMMING"></a>PROGRAMMING</h1><h2 id="Logistic-Regression"><a href="#Logistic-Regression" class="headerlink" title="Logistic Regression"></a>Logistic Regression</h2><h3 id="Visualizing-the-data"><a href="#Visualizing-the-data" class="headerlink" title="Visualizing the data"></a>Visualizing the data</h3><p>&emsp;&emsp;这一段可以自己写，但是在pdf中也有直接的代码可以添加在plotdata.m中：<br><figure class="highlight matlab"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="comment">% Find Indices of Positive and Negative Examples</span></div><div class="line">pos = <span class="built_in">find</span>(y==<span class="number">1</span>); neg = <span class="built_in">find</span>(y == <span class="number">0</span>);</div><div class="line"><span class="comment">% Plot Examples</span></div><div class="line">plot(X(pos, <span class="number">1</span>), X(pos, <span class="number">2</span>), <span class="string">'k+'</span>,<span class="string">'LineWidth'</span>, <span class="number">2</span>, <span class="string">'MarkerSize'</span>, <span class="number">7</span>);</div><div class="line">plot(X(neg, <span class="number">1</span>), X(neg, <span class="number">2</span>), <span class="string">'ko'</span>, <span class="string">'MarkerFaceColor'</span>, <span class="string">'y'</span>, <span class="string">'MarkerSize'</span>, <span class="number">7</span>);</div></pre></td></tr></table></figure></p>
<h3 id="Sigmoid-Function"><a href="#Sigmoid-Function" class="headerlink" title="Sigmoid Function"></a>Sigmoid Function</h3><p>&emsp;&emsp;根据公式可以直接求出。注意是点除，不是直接的相除。<br><figure class="highlight matlab"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">g=<span class="number">1.</span>/(<span class="number">1</span>+<span class="built_in">exp</span>(-z));</div></pre></td></tr></table></figure></p>
<h3 id="Cost-function-and-gradient"><a href="#Cost-function-and-gradient" class="headerlink" title="Cost function and gradient"></a>Cost function and gradient</h3><p>&emsp;&emsp;根据公式，在costFunction.m中添加以下代码：<br><figure class="highlight matlab"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">J=<span class="number">1</span>/m*(-y'*<span class="built_in">log</span>(sigmoid(X*theta))-(<span class="number">1</span>-y)'*<span class="built_in">log</span>(<span class="number">1</span>-sigmoid(X*theta)));</div><div class="line">grad=<span class="number">1</span>/m*((sigmoid(X*theta)-y)'*X);</div></pre></td></tr></table></figure></p>
<h3 id="Evaluating-logistic-regression"><a href="#Evaluating-logistic-regression" class="headerlink" title="Evaluating logistic regression"></a>Evaluating logistic regression</h3><p>&emsp;&emsp;这个就是根据结果判断是0还是1了，在predict.m中添加以下代码：<br><figure class="highlight matlab"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">h=sigmoid(X*theta);</div><div class="line">p(<span class="built_in">find</span>(h&lt;<span class="number">0.5</span>))=<span class="number">0</span>;</div><div class="line">p(<span class="built_in">find</span>(h&gt;=<span class="number">0.5</span>))=<span class="number">1</span>;</div></pre></td></tr></table></figure></p>
<h2 id="Regularized-logistic-regression"><a href="#Regularized-logistic-regression" class="headerlink" title="Regularized logistic regression"></a>Regularized logistic regression</h2><h3 id="Cost-function-and-gradient-1"><a href="#Cost-function-and-gradient-1" class="headerlink" title="Cost function and gradient"></a>Cost function and gradient</h3><p>&emsp;&emsp;在原先的基础上添加一个正则项，matlab下标从1开始，这个问题让我找了半天的bug，在costFunctionReg.m中添加以下代码：<br><figure class="highlight matlab"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">J=<span class="number">1</span>/m*(-y'*<span class="built_in">log</span>(sigmoid(X*theta))-(<span class="number">1</span>-y)'*<span class="built_in">log</span>(<span class="number">1</span>-sigmoid(X*theta)))+lambda/<span class="number">2</span>/m*(theta(<span class="number">2</span>:<span class="keyword">end</span>)'*theta(<span class="number">2</span>:<span class="keyword">end</span>));</div><div class="line">grad=<span class="number">1</span>/m*((sigmoid(X*theta)-y)'*X);</div><div class="line">grad(<span class="number">2</span>:<span class="keyword">end</span>)=grad(<span class="number">2</span>:<span class="keyword">end</span>)+lambda/m*theta(<span class="number">2</span>:<span class="keyword">end</span>)';</div></pre></td></tr></table></figure></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://115.159.44.202/2017/10/31/机器学习/多数投票分类器/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Mikito">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Mikito">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/10/31/机器学习/多数投票分类器/" itemprop="url">
                  考虑平局的投票分类器
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-10-31T12:33:29+08:00">
                2017-10-31
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/机器学习/" itemprop="url" rel="index">
                    <span itemprop="name">机器学习</span>
                  </a>
                </span>

                
                
              
            </span>
          

          

          
          

          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>&emsp;&emsp;在基础分类器中，除了最近邻的方法外，投票也是常用的一种方法。投票的原理是：每一个部分拥有一票或多票，根据一定的规则投给某一个类别，获得最多票数的类别是最终得到的类别。</p>
<h2 id="基础算法"><a href="#基础算法" class="headerlink" title="基础算法"></a>基础算法</h2><p>&emsp;&emsp;很多matlab的实现投票分类器的代码如下：<br><figure class="highlight matlab"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">a=<span class="number">1</span>:c; <span class="comment">% c是类别数</span></div><div class="line"><span class="keyword">for</span> <span class="built_in">i</span>=<span class="number">1</span>:num</div><div class="line">   h(<span class="built_in">i</span>,:)=hist(index(<span class="built_in">i</span>,:),a); <span class="comment">% index是一个矩阵,每一个位置都有一个数字，在0到c之间</span></div><div class="line"><span class="keyword">end</span></div><div class="line">[~,ind]=max(h,[],<span class="number">2</span>);</div></pre></td></tr></table></figure></p>
<p>&emsp;&emsp;我一开始也是使用这种方法做的分类，但是老师问我，如果是2：2怎么办呢？在我的实验中，我已知的是一个距离矩阵，共有length(X_tst)行，length(X_trn) <em> num列，即有多少个测试样本就有多少行，而训练样本数 </em> 分块数就是列数。在这种情况下，当分块数太小时很有可能出现平局的局面，而以上的算法并没有考虑到这个局面，它只是在平局时简单粗暴地选择了较小的序号。</p>
<h2 id="考虑到平局的算法"><a href="#考虑到平局的算法" class="headerlink" title="考虑到平局的算法"></a>考虑到平局的算法</h2><p>&emsp;&emsp;这个分类算法被我用于单样本人脸识别，因此代码可能不具有通用性，但是思想方法大体差别不大。</p>
<blockquote>
<p>输入：距离矩阵D，共有length(X_tst)行，length(X_trn) * num列。前num列存放各个测试样本到训练图片1的num块的距离。<br>输出：分类得到的结果ind<br>流程：</p>
<ol>
<li>对第$i$块，得到距离矩阵dt，表示测试样本到所有训练样本第$i$块的距离。从每个dt中得到一个最小距离向量和对应的索引向量。</li>
<li>将所有的距离向量连起来得到矩阵mindis，将所有的索引合起来得到矩阵index。</li>
<li>对每一块，用hist进行统计，并连起来。</li>
<li>求出每块中出现的最大次数times和对应的序号ind。</li>
<li>用sum和bsxfun函数一起判断有没有平局的出现。</li>
<li>对于出现平局的样本，找到平局中序号对应的最小距离，谁小测试样本就是那一类的。</li>
</ol>
</blockquote>
<p>&emsp;&emsp;比起使用for循环，matlab中更提倡矩阵的运算，所以一部分我是直接使用矩阵进行运算的。但是在处理平局时，我没有找到合适的函数。使用了两层for循环，对每一个测试样本，将距离排序，依次使用最小的距离，并判断最小的距离对应的序号是否在平局的序号中，如果不是再取第二小的，依次递推。</p>
<h2 id="matlab代码"><a href="#matlab代码" class="headerlink" title="matlab代码"></a>matlab代码</h2><figure class="highlight matlab"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div></pre></td><td class="code"><pre><div class="line">c=max(Y_trn); <span class="comment">%类别数</span></div><div class="line">num=<span class="built_in">size</span>(d,<span class="number">2</span>)/c; <span class="comment">%每个图像有多少块</span></div><div class="line">a=<span class="number">1</span>:c;</div><div class="line">index=[];</div><div class="line">mindis=[];</div><div class="line"><span class="keyword">for</span> <span class="built_in">i</span>=<span class="number">1</span>:num</div><div class="line">   dt=[];</div><div class="line">   <span class="keyword">for</span> <span class="built_in">j</span>=<span class="number">1</span>:c</div><div class="line">      dt=[dt,d(:,num*(j<span class="number">-1</span>)+i)];</div><div class="line">   <span class="keyword">end</span></div><div class="line">   [dis,ind]=min(dt,[],<span class="number">2</span>);</div><div class="line">   mindis=[mindis,dis];</div><div class="line">   index=[index,ind];</div><div class="line"><span class="keyword">end</span></div><div class="line"><span class="keyword">for</span> <span class="built_in">i</span>=<span class="number">1</span>:<span class="built_in">length</span>(Y_tst)</div><div class="line">   h(<span class="built_in">i</span>,:)=hist(index(<span class="built_in">i</span>,:),a);</div><div class="line"><span class="keyword">end</span></div><div class="line">[times,ind]=max(h,[],<span class="number">2</span>); <span class="comment">% times出现的最大次数， ind：出现的最大次数对应的序号</span></div><div class="line">bf=<span class="built_in">bsxfun</span>(@eq,h,times);</div><div class="line">s=sum(bf,<span class="number">2</span>);<span class="comment">% 最大次数出现了几次</span></div><div class="line">fd=<span class="built_in">find</span>(s~=<span class="number">1</span>); <span class="comment">% 找到出现平局的情况</span></div><div class="line">[~, id]=sort(mindis,<span class="number">2</span>);</div><div class="line"><span class="keyword">for</span> <span class="built_in">i</span>=<span class="number">1</span>:<span class="built_in">length</span>(fd)</div><div class="line">   <span class="keyword">for</span> <span class="built_in">j</span>=<span class="number">1</span>:num</div><div class="line">      <span class="keyword">if</span> bf(fd(<span class="built_in">i</span>),index(fd(<span class="built_in">i</span>),id(fd(<span class="built_in">i</span>),<span class="built_in">j</span>)))==<span class="number">1</span></div><div class="line">         ind(fd(<span class="built_in">i</span>))=index(fd(<span class="built_in">i</span>),id(fd(<span class="built_in">i</span>),<span class="built_in">j</span>));</div><div class="line">         <span class="keyword">break</span>;</div><div class="line">      <span class="keyword">end</span></div><div class="line">   <span class="keyword">end</span></div><div class="line"><span class="keyword">end</span></div></pre></td></tr></table></figure>
          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://115.159.44.202/2017/10/22/机器学习/统计学习方法/《统计学习方法》之k近邻法/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Mikito">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Mikito">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/10/22/机器学习/统计学习方法/《统计学习方法》之k近邻法/" itemprop="url">
                  《统计学习方法》之k近邻法
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-10-22T14:10:18+08:00">
                2017-10-22
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/《统计学习方法》/" itemprop="url" rel="index">
                    <span itemprop="name">《统计学习方法》</span>
                  </a>
                </span>

                
                
              
            </span>
          

          

          
          

          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>&emsp;&emsp;相似度查询有两种方法：<br>&emsp;1. 范围查询，给定阈值。<br>&emsp;2. k近邻查询，给定查询点和k。<br>&emsp;&emsp;k近邻法是一种基本分类与回归的方法。其基本思想是：一个样本的k个最相近的样本大多属于某一个类，则该样本也属于这个类。因此，k近邻算法不具有显式的学习过程。k值的选择、距离度量和分类决策规则是k近邻方法的三个基本要素。</p>
<h2 id="k近邻算法"><a href="#k近邻算法" class="headerlink" title="k近邻算法"></a>k近邻算法</h2><blockquote>
<p>k近邻算法流程<br>输入：训练数据集$T={(x_1,y_1),(x_2,y_2),…,(x_N,y_N)}$，其中，$x \in X \subseteq R^n$为实例的特征向量，$y_i\in Y={c_1,c_2,…,c_K}$为实例的类别，$i=1,2,…,N$，实例特征向量$x$。<br>输出：实例$x$所属的类$y$。<br>(1) 根据给定的距离度量，在训练集$T$中找出与$x$最近的$k$个点，涵盖这$k$个点的$x$邻域记作$N_k(x)$。<br>(2) 在$N_k(x)$中根据分类决策规则，决定$x$的类别$y$：<br>$y=\arg \max \limits_{c_j}{\sum \limits_{x_i\in N_k(x)}I(y_i=c_j)}, i=1,2,…,N; j=1,2,…,K $<br>其中$I$为指示函数，即当$y_i=c_j$时，$I$为1，否则为0。</p>
</blockquote>
<p>&emsp;&emsp;k近邻的特殊情况是当$k=1$时，此算法被称为最近邻算法。</p>
<h2 id="k近邻模型"><a href="#k近邻模型" class="headerlink" title="k近邻模型"></a>k近邻模型</h2><h3 id="模型"><a href="#模型" class="headerlink" title="模型"></a>模型</h3><p>&emsp;&emsp;特征空间中，对于每个训练实例点$x_i$，距离该点比其他店更近的所有点组成的一个区域，叫做单元。k近邻算法就是利用训练数据集对特征向量空间进行划分。</p>
<h3 id="距离度量"><a href="#距离度量" class="headerlink" title="距离度量"></a>距离度量</h3><p>&emsp;&emsp;距离度量公式定义为：<br>$$L_p(x_i,x_j)=(\sum_{l=1}^{n}|x_i^{(l)}-x_i^{(l)}|^p)^\frac{1}{p}$$<br>其中$p\geq 1$<br>&emsp;&emsp;当$p=1$时，可以得到曼哈顿距离：$L_1(x_i,x_j)=\sum_{l=1}^{n}|x_i^{(l)}-x_i^{(l)}|$<br>&emsp;&emsp;当$p=2$时，可以得到欧式距离：$L_2(x_i,x_j)=(\sum_{l=1}^{n}|x_i^{(l)}-x_i^{(l)}|^2)^\frac{1}{2}$</p>
<h3 id="k值的选择"><a href="#k值的选择" class="headerlink" title="k值的选择"></a>k值的选择</h3><p>&emsp;&emsp;k值的选择对算法有很大的影响。k值的减小意味着整体模型变得复杂，容易发生过拟合。如果选择较大的k值，可以减少学习的估计误差，但是学习的近似误差会增加。在应用中，k值一般取一个比较小的值。通常采用交叉验证法来选取最合适的k值。</p>
<h3 id="分类决策规则"><a href="#分类决策规则" class="headerlink" title="分类决策规则"></a>分类决策规则</h3><p>&emsp;&emsp;k近邻法中的分类决策规则往往是多数表决，即由输入实例的k个近邻的训练实例中的多数类决定输入实例的类。这种决策规则等价于经验风险最小化。</p>
<h2 id="k近邻法的实现：kd树"><a href="#k近邻法的实现：kd树" class="headerlink" title="k近邻法的实现：kd树"></a>k近邻法的实现：kd树</h2><p>&emsp;&emsp;我们在进行特征匹配是，通常采用两种方法：线性扫描和构建数据索引，而使用构建数据索引时，在无重叠时可采用kd树，重叠时可采用R树。<br>&emsp;&emsp;kd树的全称是k-dimension tree，可以用于k近邻的寻找。</p>
<h3 id="构造kd树"><a href="#构造kd树" class="headerlink" title="构造kd树"></a>构造kd树</h3><p>&emsp;&emsp;kd树是一棵二叉树，也是一颗空间划分树（空间划分树：将整个空间划分为几个特定的部分，然后再特定的部分进行搜索）。</p>
<blockquote>
<p>构造平衡kd树流程<br>输入：$k$维空间数据集$T={x_1,x_2,…,x_N}$，其中$x_i=(x_i^{(1)},x_i^{(2)},…,x_i^{(k)})^T，i=1,2,…,N$<br>输出：kd树<br>算法流程：<br>(1) 开始：构造根结点，根结点对应于包含$T$的$k$维空间的超矩形区域。<br>&emsp;选择$x^{(1)}$为坐标轴，将$T$中所有实例的$x^{(1)}$的中位数（奇数个：取中间，偶数个：中间偏大）为切分点，将根结点对应的超矩形区域切分成两个子区域。左子结点对应于小于切分点的子区域，有子结点对应于大于切分点的子区域。落在切分超平面上的实例点保存在根节点。<br>(2) 重复：对深度为$j$的切分点，选择$x^{(l)}$为切分的坐标轴，其中$l=j(modk)+1$（从1到$k$循环取），重复以上操作。<br>(3) 直到两个子区域没有实例点存在时停止。从而形成kd树的区域划分。</p>
</blockquote>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://115.159.44.202/2017/10/18/论文阅读/人脸识别/《Extended local binary patterns for face recognition》阅读笔记/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Mikito">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Mikito">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/10/18/论文阅读/人脸识别/《Extended local binary patterns for face recognition》阅读笔记/" itemprop="url">
                  《Extended local binary patterns for face recognition》阅读笔记
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-10-18T15:31:29+08:00">
                2017-10-18
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/论文阅读/" itemprop="url" rel="index">
                    <span itemprop="name">论文阅读</span>
                  </a>
                </span>

                
                
              
            </span>
          

          

          
          

          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="Brief-Introduction"><a href="#Brief-Introduction" class="headerlink" title="Brief Introduction"></a>Brief Introduction</h2><p>&emsp;&emsp;在原先的基础上提出了三种新的LBP算子。（后面具体的没有看）</p>
<h2 id="Proposed-Method"><a href="#Proposed-Method" class="headerlink" title="Proposed Method"></a>Proposed Method</h2><p>&emsp;&emsp; They propose a novel method based on PCA image reconstruction and LDA for face recognition. Our proposed methods effectively combine the advantages of PCA, LDA, and SVM.</p>
<h2 id="Framework"><a href="#Framework" class="headerlink" title="Framework"></a>Framework</h2><ol>
<li>Introduction<br>&emsp;1.1 人脸识别现状（十分热门+提出很多算法+缺点（有挑战性））<br>&emsp;1.2 人脸识别的关键问题（特征提取和分类器）+特征提取的重要性和挑战<br>&emsp;1.3 全局特征和局部特征+优缺点<br>&emsp;1.4 LBP的优点和缺点<br>&emsp;1.5 本文算法和主要贡献</li>
<li>Related work</li>
<li>Extended LBP descriptors<br>&emsp;3.1 Angular-differences based descriptors<br>&emsp;3.2 Radial-differences based descriptors<br>&emsp;3.3 Statistical distribution examination of patterns</li>
<li>Face representation</li>
<li>Experiments</li>
<li>Conclusions</li>
</ol>
<h2 id="Other"><a href="#Other" class="headerlink" title="Other"></a>Other</h2>
          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://115.159.44.202/2017/10/18/论文阅读/人脸识别/《A two-phase face recognition method in frequency domain》阅读笔记/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Mikito">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Mikito">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/10/18/论文阅读/人脸识别/《A two-phase face recognition method in frequency domain》阅读笔记/" itemprop="url">
                  《A two-phase face recognition method in frequency domain》阅读笔记
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-10-18T14:30:29+08:00">
                2017-10-18
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/论文阅读/" itemprop="url" rel="index">
                    <span itemprop="name">论文阅读</span>
                  </a>
                </span>

                
                
              
            </span>
          

          

          
          

          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="Brief-Introduction"><a href="#Brief-Introduction" class="headerlink" title="Brief Introduction"></a>Brief Introduction</h2><p>&emsp;&emsp;对图像进行DCT和DFT特征提取+（第一项）先求得k个近邻+将图像分成K个图片的融合，并求得每张图片对应的系数+计算测试样本和每类之间的距离</p>
<h2 id="Proposed-Method"><a href="#Proposed-Method" class="headerlink" title="Proposed Method"></a>Proposed Method</h2><p>&emsp;&emsp; They proposed a two-phase representation method that uses DCT coefficients or DFT amplitude spectra for face recognition. It is more efficient than the naïve 1 norm-based sparse representation method.</p>
<h2 id="Framework"><a href="#Framework" class="headerlink" title="Framework"></a>Framework</h2><ol>
<li>Introduction<br>&emsp;1.1 人脸识别价值+基于变换域的方法<br>&emsp;1.2 基于DCT和DFT的算法的发展和分类+基于变换域的方法的优点<br>&emsp;&emsp;1.2.1 使用一部分DCT系数和DFT幅度谱<br>&emsp;&emsp;1.2.2 使用全部DCT系数和DFT幅度谱<br>&emsp;1.3 新的二相分类方法算法+优点<br>&emsp;1.4 本文算法流程<br>&emsp;1.5 文章组织结构</li>
<li>The Proposed algorithm</li>
<li>Experimental results<br>&emsp;3.1 Performance comparison<br>&emsp;3.2 Number of DCT coefficients and DFT amplitude spectra</li>
<li>Conclusions</li>
</ol>
<h2 id="Other"><a href="#Other" class="headerlink" title="Other"></a>Other</h2><ol>
<li>离散余弦变换：discrete cosine transform</li>
<li>离散傅立叶变换：discrete Fourier transform</li>
<li>幅度谱：amplitude spectra</li>
<li>变换域：transform domain</li>
<li>整体的：holistic</li>
<li>误差：deviation </li>
</ol>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://115.159.44.202/2017/10/17/论文阅读/人脸识别/《Face recognition based on PCA image reconstruction and LDA》阅读笔记/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Mikito">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Mikito">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/10/17/论文阅读/人脸识别/《Face recognition based on PCA image reconstruction and LDA》阅读笔记/" itemprop="url">
                  《Face recognition based on PCA image reconstruction and LDA》阅读笔记
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-10-17T19:24:29+08:00">
                2017-10-17
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/论文阅读/" itemprop="url" rel="index">
                    <span itemprop="name">论文阅读</span>
                  </a>
                </span>

                
                
              
            </span>
          

          

          
          

          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="Brief-Introduction"><a href="#Brief-Introduction" class="headerlink" title="Brief Introduction"></a>Brief Introduction</h2><p>&emsp;&emsp;预处理（直方图均衡化+PCA图像重建（新）+LDA+SVM</p>
<h2 id="Proposed-Method"><a href="#Proposed-Method" class="headerlink" title="Proposed Method"></a>Proposed Method</h2><p>&emsp;&emsp; They propose a novel method based on PCA image reconstruction and LDA for face recognition. Our proposed methods effectively combine the advantages of PCA, LDA, and SVM.</p>
<h2 id="Framework"><a href="#Framework" class="headerlink" title="Framework"></a>Framework</h2><ol>
<li>Introduction<br>&emsp;1.1 人脸识别现状（概念+价值+十分热门+有挑战性）<br>&emsp;1.2 人脸识别的关键问题（特征提取和分类器）<br>&emsp;&emsp;1.2.1 PCA（由来+发展）<br>&emsp;&emsp;1.2.2 LDA（影响+思想+缺点+发展）<br>&emsp;1.3 本文算法流程+优点</li>
<li>Related algorithms<br>&emsp;2.1 Principal component analysis(PCA)<br>&emsp;2.2 Linear Discriminant Analysis(LDA)<br>&emsp;2.3 Support vector machine (SVM)</li>
<li>Face recognition based on PCA image reconstruction and LDA<br>&emsp;3.1 Image preprocessing(histogram equalization)<br>&emsp;3.2 PCA image reconstruction<br>&emsp;3.3 PCA image reconstruction and LDA for face recognition（算法流程）</li>
<li>Experimental results and discussion<br>&emsp;4.1 Experiments on ORL database<br>&emsp;4.2 Discussion</li>
<li>Conclusions</li>
</ol>
<h2 id="Sentences"><a href="#Sentences" class="headerlink" title="Sentences"></a>Sentences</h2><ol>
<li>Face recognition is a technology of using computer to analyze the face images and extract the features for recognizing the identity of the target.</li>
<li>The research of face recognition has great theoretical value, involving subjects of pattern recognition, image processing, computer vision, machine learning, physiology, and so on, and it also has a high correlation with other biometrics recognition methods. </li>
<li>In recent years, face recognition is one of the most active and challenging problems in the field of pattern recognition and artificial intelligence.</li>
</ol>
<h2 id="Other"><a href="#Other" class="headerlink" title="Other"></a>Other</h2><ol>
<li>直方图均衡化：histogram equalization</li>
</ol>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://115.159.44.202/2017/10/17/论文阅读/人脸识别/《LBP 和 HOG 的分层特征融合的人脸识别》阅读笔记/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Mikito">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Mikito">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/10/17/论文阅读/人脸识别/《LBP 和 HOG 的分层特征融合的人脸识别》阅读笔记/" itemprop="url">
                  《LBP 和 HOG 的分层特征融合的人脸识别》阅读笔记
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-10-17T16:07:29+08:00">
                2017-10-17
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/论文阅读/" itemprop="url" rel="index">
                    <span itemprop="name">论文阅读</span>
                  </a>
                </span>

                
                
              
            </span>
          

          

          
          

          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>&emsp;&emsp;使用LBP和HOG两种局部特征，并采用分层的思想，将纹理特征和边界特征融合。</p>
<h2 id="内容"><a href="#内容" class="headerlink" title="内容"></a>内容</h2><p>&emsp;&emsp;万源和李欢欢等提出了将LBP 算子和 HOG 算子进行融合, 利用分层的思想，实现局部和整体特征融合的人脸识别方法。对人脸图像进行分块提取LBP 和 HOG 特征能够反映人脸的局部特征, 进而考虑整体的 LBP 和 HOG 特征又能反映人脸的整体特征, 最终实现全局和局部特征的融合. </p>
<h2 id="组织架构"><a href="#组织架构" class="headerlink" title="组织架构"></a>组织架构</h2><ol>
<li>背景介绍<br>&emsp;1.1 人脸识别方法分类。<br>&emsp;1.2 对本文中使用的第二种算法的现状（后人的改进）进行详细介绍。<br>&emsp;1.3 提出新的算法。</li>
<li>算法描述<br>&emsp;2.1 LBP 特征<br>&emsp;2.2 HOG 特征<br>&emsp;2.3 本文特征融合方法<br>&emsp;&emsp;2.3.1 分层特征（多提取几次）<br>&emsp;&emsp;2.3.2 分层 LBP 与原始 HOG 特征的融合步骤<br>&emsp;&emsp;2.3.3 分层 LBP 与基于分层 LBP 的分层 HOG 特征的融合步骤<br>&emsp;&emsp;2.3.4 相似性度量方法 </li>
<li>仿真实验与实验分析<br>&emsp;3.1 实验环境及预处理<br>&emsp;3.2 特征融合算法比较（介绍对比方法）<br>&emsp;3.3 ORL 人脸库实验结果分析<br>&emsp;&emsp;3.3.1 分块大小的比较<br>&emsp;&emsp;3.3.2 相似性度量方法比较<br>&emsp;&emsp;3.3.3 融合方法效果图<br>&emsp;3.4 Yale 人脸库实验结果分析<br>&emsp;&emsp;3.4.1 分块大小的比较<br>&emsp;&emsp;3.4.2 相似性度量方法比较<br>&emsp;&emsp;3.4.3 融合方法效果图<br>&emsp;3.5 Yale 人脸库实验结果分析<br>&emsp;&emsp;3.5.1 分块大小的比较<br>&emsp;&emsp;3.5.2 相似性度量方法比较<br>&emsp;&emsp;3.5.3 融合方法效果图<br>&emsp;3.6 时间复杂度分析<br>&emsp;3.7 算法性能评价（排序值评测法）</li>
<li>结论</li>
</ol>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ol>
<li><p>人脸识别常用的方法主要有 2 种：<br>&emsp;(1)基于全局特征的人脸识别技术, 其核心思想是将高维的人脸图像特征通过线性或非线性变化映射到一个低维的子空间中, 使得原始样本特征在这个低维子空间中更易于分类。全局特征能够有效地表示人脸的整体轮廓, 经典的方法是主成分分析(principle component analysis, PCA)、线性判别分析(linear discriminant analysis, LDA)、独立成分分析(independent component analysis, ICA)等.<br>&emsp;(2)一种是基于局部特征的人脸识别技术, 局部特征侧重于反映人脸的细节特征, 其中广泛使用的有局部二值模式(local binary pattern, LBP)、尺度不变特征变换 (scale invariant feature transform,SIFT)以及梯度方向直方图(histogram of orientedgradient, HOG)等.</p>
</li>
<li><p>LBP 特征主要提取图像的纹理信息, HOG 特征可以提取图像完整的边缘和形状信息, 并利用纹理信息和边缘轮廓信息的互补性提高识别率, 且将局部特征和整体特征相结<br>合, 进一步将分层信息融合进行人脸识别。</p>
</li>
</ol>
<h2 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h2><ol>
<li>分类器中使用的距离被称为：相似性度量方法。</li>
</ol>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://115.159.44.202/2017/10/17/论文阅读/人脸识别/《Face recognition based on PCA and logistic regression analysis》阅读笔记/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Mikito">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Mikito">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/10/17/论文阅读/人脸识别/《Face recognition based on PCA and logistic regression analysis》阅读笔记/" itemprop="url">
                  《Face recognition based on PCA and logistic regression analysis》阅读笔记
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-10-17T16:07:29+08:00">
                2017-10-17
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/论文阅读/" itemprop="url" rel="index">
                    <span itemprop="name">论文阅读</span>
                  </a>
                </span>

                
                
              
            </span>
          

          

          
          

          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="Brief-Introduction"><a href="#Brief-Introduction" class="headerlink" title="Brief Introduction"></a>Brief Introduction</h2><p>&emsp;&emsp;使用PCA进行特征提取，使用LRC作为分类器。</p>
<h2 id="Proposed-Method"><a href="#Proposed-Method" class="headerlink" title="Proposed Method"></a>Proposed Method</h2><p>&emsp;&emsp;ChangjunZhou proposed a novel face recognition method which is based on PCA and logistic regression.By combining the advantages of both the PCA and logistic regression, they use PCA to extract feature and reduce the dimensions of process data and use logistic regression as the classifier for face recognition.</p>
<h2 id="Framework"><a href="#Framework" class="headerlink" title="Framework"></a>Framework</h2><p>1 Introduction<br>&emsp;1.1 人脸识别现状（十分热门，但是有挑战性+影响因素，提出了很多方法）<br>&emsp;1.2 文章解决的两类问题<br>&emsp;&emsp;1.2.1 特征提取（PCA由来+简介）<br>&emsp;&emsp;1.2.2 分类器（分类器简介+SVM优点缺点+LRC算法简介和进化）<br>&emsp;1.3 本文算法优点<br>&emsp;1.4 文章组织结构<br>2 Related algorithms<br>&emsp;2.1 Principal component analysis(PCA)<br>&emsp;2.2 Logistic regression analysis<br>3 Proposed face recognition method（算法的流程）<br>4 Experimental results and discussion<br>&emsp;4.1 Yale database<br>&emsp;4.2 ORL database<br>5 Conclusions</p>
<h2 id="Sentences"><a href="#Sentences" class="headerlink" title="Sentences"></a>Sentences</h2><ol>
<li>Face recognition is an important research hotspot in the fields of pattern recognition and artificial intelligence, and it has attained great success in recent years.</li>
<li>Assume we have a training set …… with N images,belonging to c classes.</li>
<li>First, we preprocessed the input images, mainly including histogram equalization, geometry normalization, in order to remove the illuminations, shades, and lighting effects possibly, and then partitioned into a training set from face database and the rest is a testing set.</li>
<li>To illustrate the efficacy of our proposed method, we compared the performances on two standard databases, i.e., Yale database and the ORL database.</li>
<li>The Yale face database contains images with major variations, including changes in illumination conditions, subjects wearing eyeglasses and different facial expressions. This database involves 165 frontal facial images, with 11 images of 15 individuals.</li>
<li>To evaluate the effectiveness of the algorithms better, each image is scaled down to the size of 100 × 100 pixels.</li>
</ol>
<h2 id="Other"><a href="#Other" class="headerlink" title="Other"></a>Other</h2><ol>
<li>类间离散矩阵：between-class scatter matrix</li>
<li>类内离散矩阵：within-class scatter matrix</li>
</ol>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://115.159.44.202/2017/10/16/机器学习/Andrew/Machine Learning 第一周和第二周/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Mikito">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Mikito">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/10/16/机器学习/Andrew/Machine Learning 第一周和第二周/" itemprop="url">
                  Machine Learning 第一周和第二周
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-10-16T09:53:48+08:00">
                2017-10-16
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/机器学习/" itemprop="url" rel="index">
                    <span itemprop="name">机器学习</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>&emsp;&emsp;一直有想看Andrew Ng的机器学习课程，但是拖了很久都没有看完。之前也写过一些相关的博客，但是在博客搬家的时候没有保存下来。<br>&emsp;&emsp;第一周和第二周的内容比较少，作业也是在一起布置的。</p>
<h1 id="WEEK-1"><a href="#WEEK-1" class="headerlink" title="WEEK 1"></a>WEEK 1</h1><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><h3 id="What-is-machine-learning"><a href="#What-is-machine-learning" class="headerlink" title="What is machine learning?"></a>What is machine learning?</h3><ol>
<li>机器学习的定义：为了完成某个目标T，从经验E中学习，同时具有一定的判断标准P。</li>
</ol>
<h3 id="Supervised-Learning"><a href="#Supervised-Learning" class="headerlink" title="Supervised Learning"></a>Supervised Learning</h3><ol>
<li>监督学习：部分样本已有正确的结果。</li>
<li>分类：<br>&emsp;回归问题（regression）：预测输出结果是连续值。<br>&emsp;分类问题（classification）：预测输出结果是离散值。</li>
</ol>
<h3 id="Unsupervised-Learning"><a href="#Unsupervised-Learning" class="headerlink" title="Unsupervised Learning"></a>Unsupervised Learning</h3><ol>
<li>从数据本身的结构中得到模型。</li>
<li>预测结果无反馈。</li>
</ol>
<h2 id="Linear-Regression-with-One-Variable（单变量线性回归）"><a href="#Linear-Regression-with-One-Variable（单变量线性回归）" class="headerlink" title="Linear Regression with One Variable（单变量线性回归）"></a>Linear Regression with One Variable（单变量线性回归）</h2><h3 id="Model-Representation"><a href="#Model-Representation" class="headerlink" title="Model Representation"></a>Model Representation</h3><ol>
<li>符号定义：<br>&emsp;$m$：训练样本数<br>&emsp;$x’s$：输入变量<br>&emsp;$y$：输出变量<br>&emsp;$(x,y)$：一个训练样本<br>&emsp;$(x^{(i)},y^{(i)})$：第$i$个训练样本</li>
</ol>
<h3 id="Cost-Function"><a href="#Cost-Function" class="headerlink" title="Cost Function"></a>Cost Function</h3><ol>
<li>假设函数：$h_\theta(x)=\theta_0+\theta_1x$</li>
<li>代价函数（误差平方函数）：$J(\theta_0,\theta_1)=\frac{1}{m}\sum_{i=1}^{m}(h_{\theta}(x_i)-y_i)^2$</li>
<li>目标：最小化代价函数&emsp; $minmize J(\theta_0,\theta_1)$</li>
</ol>
<h3 id="Cost-Function-Intuition-1"><a href="#Cost-Function-Intuition-1" class="headerlink" title="Cost Function-Intuition 1"></a>Cost Function-Intuition 1</h3><h3 id="Cost-Function-Intuition-2"><a href="#Cost-Function-Intuition-2" class="headerlink" title="Cost Function-Intuition 2"></a>Cost Function-Intuition 2</h3><ol>
<li>$h_\theta(x)$是关于$x$的函数，$J(\theta_0,\theta_1)$是关于$\theta_0,\theta_1$的函数。</li>
<li>可以通过轮廓图来判断$\theta_0,\theta_1$和$J(\theta_0,\theta_1)$的关系。</li>
</ol>
<h3 id="Gradient-Descent（梯度下降）"><a href="#Gradient-Descent（梯度下降）" class="headerlink" title="Gradient Descent（梯度下降）"></a>Gradient Descent（梯度下降）</h3><ol>
<li>思想：<br>&emsp;(1). 选取一组$\theta_0,\theta_1$（通常都为0）<br>&emsp;(2). 不断更新$\theta_0$和$\theta_1$，直到$J(\theta_0,\theta_1)$达到局部最小值。<blockquote>
<p>repeat until covergence{<br>&emsp;&emsp;$\theta_j:=\theta_j-\alpha\frac{d}{d\theta_j}J(\theta_0,\theta_1)$<br>}</p>
</blockquote>
</li>
</ol>
<p>&emsp;其中$\alpha$是学习速率</p>
<ol>
<li>在变量更新过程中应保持同步更新。</li>
</ol>
<h3 id="Gradient-Descent-Intuition"><a href="#Gradient-Descent-Intuition" class="headerlink" title="Gradient Descent Intuition"></a>Gradient Descent Intuition</h3><ol>
<li>$\alpha$（学习速率）：<br>&emsp;(1). 过大，可能无法达到局部最低点。<br>&emsp;(2). 过小，十分缓慢地达到局部最低点。</li>
<li>通常，越靠近最低点，曲线的斜率越靠近0，迈的步子越小，所以没有必要在过程中修改$_alpha$。</li>
</ol>
<h3 id="Gradient-Descent-For-Linear-Regression"><a href="#Gradient-Descent-For-Linear-Regression" class="headerlink" title="Gradient Descent For Linear Regression"></a>Gradient Descent For Linear Regression</h3><ol>
<li>对变量的改变的求导展开为<br>&emsp;$\theta_0:=\theta_0-\alpha\frac{1}{m}\sum_{i=1}^{m}(h_{\theta}(x_i)-y_i)$<br>&emsp;$\theta_1:=\theta_1-\alpha\frac{1}{m}\sum_{i=1}^{m}(h_{\theta}(x_i)-y_i)\cdot x_i$</li>
</ol>
<h2 id="Linear-Algebra-Review"><a href="#Linear-Algebra-Review" class="headerlink" title="Linear Algebra Review"></a>Linear Algebra Review</h2><h3 id="Matrices-and-Vextors"><a href="#Matrices-and-Vextors" class="headerlink" title="Matrices and Vextors"></a>Matrices and Vextors</h3><ol>
<li>一般使用大写字母表示矩阵，小写字母表示向量。</li>
<li>$R$表示实数集，$R^n$表示由实数集组成的$n$维向量。</li>
</ol>
<h3 id="Addition-and-Scalar-Multiplication"><a href="#Addition-and-Scalar-Multiplication" class="headerlink" title="Addition and Scalar Multiplication"></a>Addition and Scalar Multiplication</h3><ol>
<li>Scalar Multiplication：标量乘法，即一个实数乘以一个矩阵。</li>
</ol>
<h3 id="Matrix-Vector-Multiplication"><a href="#Matrix-Vector-Multiplication" class="headerlink" title="Matrix Vector Multiplication"></a>Matrix Vector Multiplication</h3><ol>
<li>一个$m\times n$的矩阵与一个$n\times 1$的向量相乘的结果是一个$m\times 1$的向量。</li>
</ol>
<h3 id="Matrix-Matrix-Multiplication"><a href="#Matrix-Matrix-Multiplication" class="headerlink" title="Matrix Matrix Multiplication"></a>Matrix Matrix Multiplication</h3><ol>
<li>一个$m\times n$的矩阵与一个$n\times o$的矩阵相乘的结果是一个$m\times o$的矩阵。</li>
</ol>
<h3 id="Matrix-Multiplication-Properties（矩阵乘法的特性）"><a href="#Matrix-Multiplication-Properties（矩阵乘法的特性）" class="headerlink" title="Matrix Multiplication Properties（矩阵乘法的特性）"></a>Matrix Multiplication Properties（矩阵乘法的特性）</h3><h3 id="Inverse-and-Transpose"><a href="#Inverse-and-Transpose" class="headerlink" title="Inverse and Transpose"></a>Inverse and Transpose</h3><ol>
<li>$A$的逆矩阵为$A^{-1}$。</li>
<li>一个非方阵的矩阵无逆矩阵。</li>
</ol>
<h1 id="WEEK-2"><a href="#WEEK-2" class="headerlink" title="WEEK 2"></a>WEEK 2</h1><h2 id="Multivariate-Linear-Regression（多元线性回归）"><a href="#Multivariate-Linear-Regression（多元线性回归）" class="headerlink" title="Multivariate Linear Regression（多元线性回归）"></a>Multivariate Linear Regression（多元线性回归）</h2><h3 id="Multiple-Features"><a href="#Multiple-Features" class="headerlink" title="Multiple Features"></a>Multiple Features</h3><ol>
<li>符号定义：<br>&emsp;$n$：特征的数量<br>&emsp;$x^{(i)}$：第$i$个样本的特征<br>&emsp;$x_{j}^{(i)}$：第$i$个样本的第$j$个特征</li>
</ol>
<h3 id="Gradient-Descent-for-Multiple-Variables"><a href="#Gradient-Descent-for-Multiple-Variables" class="headerlink" title="Gradient Descent for Multiple Variables"></a>Gradient Descent for Multiple Variables</h3><ol>
<li>假设：$h_\theta(x)=\theta^Tx=\theta_0x_0+\theta_1x_1+…+\theta_nx_n$，其中$x_0=1$。</li>
<li>变量：$\theta=[\theta_0,\theta_1,…,\theta_n]^T$</li>
<li>代价函数：$J(\theta_0,\theta_1)=\frac{1}{m}\sum_{i=1}^{m}(h_{\theta}(x_i)-y_i)^2$</li>
<li>更新：<blockquote>
<p>repeat until covergence{<br>&emsp;&emsp;$\theta_j:=\theta_j-\alpha\frac{1}{m}h_{theta}(x_i)-y_i)x_{j}^{(i)}$<br>}</p>
</blockquote>
</li>
</ol>
<h3 id="Gradient-Descent-in-Practice-1-Feature-Scaling（特征缩放）"><a href="#Gradient-Descent-in-Practice-1-Feature-Scaling（特征缩放）" class="headerlink" title="Gradient Descent in Practice 1-Feature Scaling（特征缩放）"></a>Gradient Descent in Practice 1-Feature Scaling（特征缩放）</h3><ol>
<li>特征的尺度相似时，梯度下降进行得更快。</li>
<li>均一化（Mean normalization）：$x_i=\frac{x_i-\mu_i}{s_i}$，其中$\mu_i$是均值，$s_i$是范围（最大值-最小值）</li>
</ol>
<h3 id="Gradient-Descent-in-Practice-2-Learning-rate"><a href="#Gradient-Descent-in-Practice-2-Learning-rate" class="headerlink" title="Gradient Descent in Practice 2-Learning rate"></a>Gradient Descent in Practice 2-Learning rate</h3><ol>
<li>可以通过画$J(\theta)$和迭代次数的关系曲线图，来判断$\alpha$的选择是否正确。</li>
<li>正常情况下，$J(\theta)$会随着迭代次数的增加而减小。</li>
<li>$J(\theta)$下降得很慢，则$\alpha$过小。</li>
<li>$J(\theta)$上升或者不是持续下降，则$\alpha$过大。</li>
</ol>
<h3 id="Features-and-Polynomial-Regression"><a href="#Features-and-Polynomial-Regression" class="headerlink" title="Features and Polynomial Regression"></a>Features and Polynomial Regression</h3><ol>
<li>改进假设函数的方法：<br>&emsp;(1). 将多个特征合为一个特征。<br>&emsp;(2). 多项式回归。</li>
</ol>
<h2 id="Computing-Parameters-Analytically"><a href="#Computing-Parameters-Analytically" class="headerlink" title="Computing Parameters Analytically"></a>Computing Parameters Analytically</h2><h3 id="Normal-Equation（正规方程）"><a href="#Normal-Equation（正规方程）" class="headerlink" title="Normal Equation（正规方程）"></a>Normal Equation（正规方程）</h3><ol>
<li>正规方程求解$\theta$时可以一步到位。</li>
<li>假设有$m$个变量，每个变量有$n$个特征。<br>构建$X=\begin{bmatrix}<br>1 &amp; 1 &amp; … &amp; 1 \\<br>x^{(1)} &amp; x^{(1)} &amp; … &amp; x^{(m)}<br>\end{bmatrix} ^T$，$Y=[y^{(1)},y^{(2)},…,y^{(m)}]^T$<br>$X\theta = Y$<br>所以$\theta =(X^TX)^{-1}X^TY$</li>
<li>对正规方程来说，没有必要使用特征缩放。</li>
<li>正规方程：$\theta \in R^{n+1}$，即求得$\theta _0,\theta _1, …,\theta _n$<br>使得$\frac{d}{d\theta _j}J(\theta )=…=0$，其中$J(\theta_0,\theta_1)=\frac{1}{m}\sum_{i=1}^{m}(h_{\theta}(x_i)-y_i)^2$。</li>
<li>对比：<br>|梯度下降|正规方程|<br>|:–:|:–:|<br>|需要选择$\alpha$|不需要选择$\alpha$|<br>|需要迭代|不需要迭代|<br>|时间复杂度$O(n^2)$|时间复杂度$O(n^3)$|<br>|$n$大时也有效|当$n$大时，运行缓慢|</li>
<li>$n\leq 10000$，可选择正规方程求解。</li>
</ol>
<h3 id="Normal-Equation-Noninvertibility（不可逆性）"><a href="#Normal-Equation-Noninvertibility（不可逆性）" class="headerlink" title="Normal Equation Noninvertibility（不可逆性）"></a>Normal Equation Noninvertibility（不可逆性）</h3><ol>
<li>$X^TX$不可逆的原因可能为：<br>&emsp;(1). 特征之间关联大。<br>&emsp;(2). 特征数量太多。</li>
</ol>
<h1 id="PROGRAMMING"><a href="#PROGRAMMING" class="headerlink" title="PROGRAMMING"></a>PROGRAMMING</h1><h2 id="warmUpExercise"><a href="#warmUpExercise" class="headerlink" title="warmUpExercise"></a>warmUpExercise</h2><p>&emsp;&emsp;在warmUpExercise.m中添加：<br><figure class="highlight matlab"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">A = <span class="built_in">eye</span>(<span class="number">5</span>);</div></pre></td></tr></table></figure></p>
<h2 id="Linear-regression-with-one-variable"><a href="#Linear-regression-with-one-variable" class="headerlink" title="Linear regression with one variable"></a>Linear regression with one variable</h2><h3 id="computeCost"><a href="#computeCost" class="headerlink" title="computeCost"></a>computeCost</h3><p>&emsp;&emsp;在computeCost.m中添加：<br><figure class="highlight matlab"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">ypre=X*theta;</div><div class="line">J=<span class="number">1</span>/<span class="number">2</span>/m*sum((ypre-y).^<span class="number">2</span>);</div></pre></td></tr></table></figure></p>
<h3 id="gradientDescent"><a href="#gradientDescent" class="headerlink" title="gradientDescent"></a>gradientDescent</h3><p>&emsp;&emsp;gradientDescent.m中添加：<br><figure class="highlight matlab"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">theta=theta-(alpha/m*sum(<span class="built_in">bsxfun</span>(@times,X*theta-y,X)))';</div></pre></td></tr></table></figure></p>
<h2 id="Linear-regression-with-multiple-variables"><a href="#Linear-regression-with-multiple-variables" class="headerlink" title="Linear regression with multiple variables"></a>Linear regression with multiple variables</h2><h3 id="Feature-Normalization"><a href="#Feature-Normalization" class="headerlink" title="Feature Normalization"></a>Feature Normalization</h3><p>&emsp;&emsp;在featureNormalize.m中添加：<br><figure class="highlight matlab"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">mu=mean(X);</div><div class="line">sigma=std(X);</div><div class="line">X_norm=<span class="built_in">bsxfun</span>(@rdivide,<span class="built_in">bsxfun</span>(@minus,X,mu),sigma);</div></pre></td></tr></table></figure></p>
<h3 id="computeCostMulti"><a href="#computeCostMulti" class="headerlink" title="computeCostMulti"></a>computeCostMulti</h3><p>&emsp;&emsp;在computeCostMulti.m中添加：<br><figure class="highlight matlab"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">ypre=X*theta;</div><div class="line">J=<span class="number">1</span>/<span class="number">2</span>/m*sum((ypre-y).^<span class="number">2</span>);</div></pre></td></tr></table></figure></p>
<h3 id="gradientDescentMulti"><a href="#gradientDescentMulti" class="headerlink" title="gradientDescentMulti"></a>gradientDescentMulti</h3><p>&emsp;&emsp;在gradientDescentMulti.m中添加：<br><figure class="highlight matlab"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">theta=theta-(alpha/m*sum(<span class="built_in">bsxfun</span>(@times,X*theta-y,X)))';</div></pre></td></tr></table></figure></p>
<p>&emsp;&emsp;在ex1_multi.m中修改：<br><figure class="highlight matlab"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">price = [<span class="number">1650</span>,<span class="number">3</span>];</div><div class="line">price=[<span class="number">1</span>,(price-mu)./sigma] * theta;</div></pre></td></tr></table></figure></p>
<h2 id="normalEqn"><a href="#normalEqn" class="headerlink" title="normalEqn"></a>normalEqn</h2><p>&emsp;&emsp;normalEqn.m中添加：<br><figure class="highlight matlab"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">theta=X'*X \ X'*y;</div></pre></td></tr></table></figure></p>
<p>&emsp;&emsp;在ex1_multi.m中修改：<br><figure class="highlight matlab"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">price = [<span class="number">1</span>,<span class="number">1650</span>,<span class="number">3</span>];</div><div class="line">price=price* theta;</div></pre></td></tr></table></figure></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://115.159.44.202/2017/10/10/随记/从苏大到东南，四年又三年/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Mikito">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Mikito">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/10/10/随记/从苏大到东南，四年又三年/" itemprop="url">
                  从苏大到东南，四年又三年
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-10-10T17:02:29+08:00">
                2017-10-10
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/随记/" itemprop="url" rel="index">
                    <span itemprop="name">随记</span>
                  </a>
                </span>

                
                
              
            </span>
          

          

          
          

          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>&emsp;&emsp;保研的所有在9月28日定下来了，最后去了东南大学计算机科学与工程学院，进了PALM实验室，以后可能会做自然语言处理。</p>
<h2 id="前期准备"><a href="#前期准备" class="headerlink" title="前期准备"></a>前期准备</h2><p>&emsp;&emsp;在我高考炸了报考苏大的时候，就准备读研了。当时还想着读了其他专业转专业到金融来着，但是读了一年计算机觉得也可以，比金融好一些，就放弃了转专业。但是从始至终我都知道自己是要读研究生的，所以也不存在晃晃荡荡的。绩点也还可以，保证我可以拿到校内的保研名额，也没有挂过科。<br>&emsp;&emsp;科研方面，很多人加入了ACM，然后去打比赛，拿铜牌银牌金牌，我认识一个保研去了南大现在在微软实习的大佬就是拿了金牌，当然他本身就很厉害。我是在大一的时候，在一个老师的介绍下加入了机器学习课题组，做单样本人脸识别相关的实验，然后写了一篇很简单的英文论文。但是在高校夏令营开始的时候论文还没录用，所以很多夏令营我都不敢去。<br>&emsp;&emsp;保研是一个长期工作，大概前期就是保持成绩好，然后做一些项目来充实自己，让简历有东西可填，自我介绍的时候有话可以说。</p>
<h2 id="PALM实验室面试"><a href="#PALM实验室面试" class="headerlink" title="PALM实验室面试"></a>PALM实验室面试</h2><p>&emsp;&emsp;在一个学长的介绍下知道了PALM实验室，听说很厉害的样子，耿新老师很有名，虽然在网上并不能查到什么资料。6月末，有个原先是苏大后来去了东南的师兄在隔壁班的群里发了PALM的面试招生的要求，潘大佬顺带发给了我，然后我们就兴冲冲地报了名。<br>&emsp;&emsp;报名就是给薛晖老师发了一封邮件，附件是自己的简历。最好提前就准备一份好看的简历，可以参考下网上的一些要求。多检查几次，我就是第一次发错了，然后又重发的。邮件正文最好也是写一些东西，以表现出自己的真诚和期待。<br>&emsp;&emsp;在发了简历之后几天，就收到了实验室的面试通知，基本上身边的发了都收到了，然后大家就组团去面试。面试要求准备一份PPT和对应的自我介绍。经验就是，PPT保持16：9就好，然后放在U盘的根目录下，以自己的姓名保存。<br>&emsp;&emsp;面试的教室就像一般的会议室，老师坐在对面，学生坐在另一边，用电脑进行幻灯片的放映和介绍。老师会根据你的PPT来对你进行提问，并不是很严肃的，就是像聊天一样。当时我还太紧张，有些没有听清。大概十分钟左右就结束了。出来和他们聊天，发现如果老师对你有兴趣，就会多问一些问题。所以有什么特长啊，不要藏着掖着，在自我介绍的时候要说出来。<br>&emsp;&emsp;面试的当晚11点左右，就收到了实验室通过的邮件，并给我分了老师。然后就是和分配的老师邮件交流之类的。这个是后话了。<br>&emsp;&emsp;另外在东南预招生结束后一般PALM实验室也会有一次招生，不过那次竞争就比较激烈了。当然，对大佬不存在问题。</p>
<h2 id="东南预招生"><a href="#东南预招生" class="headerlink" title="东南预招生"></a>东南预招生</h2><p>&emsp;&emsp;东南预招生报名时间比较长，去考试的时后也比较晚了，在8月28日-8月29日。预招生的报考专业在之后可以修改，所以在联系老师之后发现老师与报考方向不同也没有问题，在录取后会有一次更改的机会。我当时报了计科，然而最后还是滚去了软件工程。<br>&emsp;&emsp;笔试考的是操作系统和数据结构两门。考试时间好像是100分钟，大概有十道题左右。操作系统比较简单，数据结构比较难。操作系统考到了了甘特图，数据结构考了平衡树的插入与删除、数据的保存、算法的实现（在O(n)的时间复杂度中实现判断链表保存的字符串是不是回文），其余的我不记得了。我大概复习了一个月的数据结构和操作系统，操作系统是将考研的书看了一遍，数据结构是借的学校的一本书，看完还是很有收获的。<br>&emsp;&emsp;笔试玩就是导师介绍，然而并没有，只有一个教务处老师来和我们说了一些注意事项。<br>&emsp;&emsp;面试分组我被分到了第一个，这导致了我前一天晚上完全没有睡好。当然可能我是第一个，我面试的时候老师也没准备好，就让我做了一下中文的自我介绍，以及问了我报考了哪些学校就让我出去了。一脸懵逼。不是说好的会考英文的么？准备了一个晚上的英文和项目介绍，3分钟我就结束了我的面试。当然在事后听说有全英文面试的，室友也是被怼的体无完肤，但是凭借良好的认错态度也过了。提问的问题基本和报考的方向有关，可以事先准备一下。<br>&emsp;&emsp;在9月3日左右出了结果，可以在官网看到。</p>
<h2 id="苏大保研名额"><a href="#苏大保研名额" class="headerlink" title="苏大保研名额"></a>苏大保研名额</h2><p>&emsp;&emsp;我原来以为苏大保研名额很好拿的，所以浪到6号才回的学校。然而一回学校就通知我9月14日就要考试。我又开始手忙脚乱地准备学校的保研考试。软件工程大概就是4-5个名额的样子，说好的10%都是骗人的。考试分为上机和面试两个部分。上机总分100分，选择50分，编程50分，最后再把总分乘以1.2，所以是120分。面试80分。上机的准备就是把往年的题目做一遍，我是每天三题做，选择就是一份一份地刷。如果开始的早的话，可以先把C语言书看一遍。<br>&emsp;&emsp;苏大编程基本三个类型：一是超简单的C语言考试的水平，二是字典树这种和字符串有关的，三是和坐标、点有关的。和出试卷的老师有关。刷一遍往年的就差不多了。<br>&emsp;&emsp;面试基本靠运气抽题，抽到好就简单。然而我们那组的面试老师有院长，基本都是被怼的体无完肤。这个，主要还是看平时和老师的关系吧。</p>
<h2 id="其余一些话"><a href="#其余一些话" class="headerlink" title="其余一些话"></a>其余一些话</h2><p>&emsp;&emsp;厉害的大佬们都去了清华北大中科院浙大啊等等等等，有兴趣的可以都去试试，反正除了车费和住宿也不花啥钱，万一中了还有个好大学。我就是太怂不敢去。其实去的多的同学说，问的问题都是差不多的，之前回答不出来，回来准备下，下次就能答出来了。<br>&emsp;&emsp;关于南大，南大今年我们学校的专业第一也不要，只要大佬。绝望.jpg。<br>&emsp;&emsp;祝看到的各位前程似锦。（虽然我觉得我的并不能被检索到）</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
  </section>

  
  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><span class="space">&hellip;</span><a class="page-number" href="/page/4/">4</a><a class="extend next" rel="next" href="/page/2/"><i class="fa fa-angle-right"></i></a>
  </nav>


          
          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      

      <section class="site-overview sidebar-panel sidebar-panel-active">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="/images/avatar.gif"
               alt="Mikito" />
          <p class="site-author-name" itemprop="name">Mikito</p>
           
              <p class="site-description motion-element" itemprop="description">Computer Science</p>
          
        </div>
        <nav class="site-state motion-element">

          
            <div class="site-state-item site-state-posts">
              <a href="/archives">
                <span class="site-state-item-count">31</span>
                <span class="site-state-item-name">日志</span>
              </a>
            </div>
          

          
            
            
            <div class="site-state-item site-state-categories">
              <a href="/categories/index.html">
                <span class="site-state-item-count">10</span>
                <span class="site-state-item-name">分类</span>
              </a>
            </div>
          

          
            
            
            <div class="site-state-item site-state-tags">
              <a href="/tags/index.html">
                <span class="site-state-item-count">31</span>
                <span class="site-state-item-name">标签</span>
              </a>
            </div>
          

        </nav>

        
          <div class="feed-link motion-element">
            <a href="/atom.xml" rel="alternate">
              <i class="fa fa-rss"></i>
              RSS
            </a>
          </div>
        

        <div class="links-of-author motion-element">
          
        </div>

        
        

        
        

        


      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright" >
  
  &copy; 
  <span itemprop="copyrightYear">2018</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Mikito</span>
</div>


<div class="powered-by">
  由 <a class="theme-link" href="https://hexo.io">Hexo</a> 强力驱动
</div>

<div class="theme-info">
  主题 -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Muse
  </a>
</div>


        

        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    
    
  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  




  
  <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.0"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.0"></script>



  
  

  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.0"></script>



  



  




	





  





  





  



  
  

  

  

  

  


  

</body>
</html>
